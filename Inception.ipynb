{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toka-amer/Sport-Image-Classification/blob/main/Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd8zedQ9mjZk",
        "outputId": "e412d2a4-dbf2-4516-98ad-a3d5465828d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=75d9286311c5bd2875f315658c4ed46676de10bdab0e0201aa84a4a1d3aab0f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9b/15/cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D,  \\\n",
        "    Dropout, Dense, Input, concatenate,      \\\n",
        "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
        "    Flatten\n",
        "from keras.datasets import cifar10 \n",
        "from keras import backend as K \n",
        "from keras.utils import np_utils\n",
        "import math \n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/MyDrive/',force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRcMWs0ZnMGS",
        "outputId": "1ad6d576-69fb-4b64-b8a9-e7d8bc1e89f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !unzip '/content/MyDrive/MyDrive/NN Dataset.zip'"
      ],
      "metadata": {
        "id": "hkWfgSxsn84r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img,transform):\n",
        "  img = PIL.Image.open(img)\n",
        "  print(img)\n",
        "  fig,ax = plt.subplots(1,2,figsize = (15,4))\n",
        "  ax[0].set_title(f'original image {img.size}')\n",
        "  ax[0].imshow(img)\n",
        "  img = transform(img)\n",
        "  ax[1].set_title(f'tansformed image {img.size}')\n",
        "  ax[1].imshow(img)"
      ],
      "metadata": {
        "id": "2MpYGw8coGAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = \"/content/Train\"\n",
        "TEST_DIR = '/content/Test'\n",
        "IMG_SIZE = 224\n",
        "LR = 0.001\n",
        "MODEL_NAME = 'AlexNet'\n",
        "\n",
        "Basketball = []\n",
        "Football = [] \n",
        "Rowing = []\n",
        "Swimming = []\n",
        "Tennis = []\n",
        "Yoga = []\n",
        "\n",
        "for img in tqdm(os.listdir(TRAIN_DIR)):\n",
        "  path = os.path.join(TRAIN_DIR,img)\n",
        "  image = cv2.imread(path,1)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  if img.__contains__(\"Basketball\"):\n",
        "    Basketball.append([np.array(image), np.array([1,0,0,0,0,0])])\n",
        "  elif img.__contains__(\"Football\"):\n",
        "    Football.append([np.array(image), np.array([0,1,0,0,0,0])])\n",
        "  elif img.__contains__(\"Rowing\"):\n",
        "    Rowing.append([np.array(image), np.array([0,0,1,0,0,0])])\n",
        "  elif img.__contains__(\"Swimming\"):\n",
        "    Swimming.append([np.array(image), np.array([0,0,1,0,0,0])])\n",
        "  elif img.__contains__(\"Tennis\"):\n",
        "    Tennis.append([np.array(image), np.array([0,0,0,0,1,0])])\n",
        "  elif img.__contains__(\"Yoga\"):\n",
        "    Yoga.append([np.array(image), np.array([0,0,0,0,0,1])])\n",
        "print(\" \")\n",
        "print(\"number of each class\")\n",
        "print(len(Basketball))\n",
        "print(len(Football))\n",
        "print(len(Rowing))\n",
        "print(len(Swimming))\n",
        "print(len(Tennis))\n",
        "print(len(Yoga))\n",
        "\n",
        "####balance dataset by flip horizantal######\n",
        "def augmentationFlipHorizontal(data,name):\n",
        "  for img in data:\n",
        "    if len(data) != 458:\n",
        "      flappedImage = cv2.flip(image,1)\n",
        "      if name == \"Basketball\":\n",
        "        Basketball.append([np.array(flappedImage), np.array([1,0,0,0,0,0])])\n",
        "      elif name == \"Football\":\n",
        "        Football.append([np.array(flappedImage), np.array([0,1,0,0,0,0])])\n",
        "      elif name == \"Rowing\":\n",
        "        Rowing.append([np.array(flappedImage), np.array([0,0,1,0,0,0])])\n",
        "      elif name == \"Swimming\":\n",
        "        Swimming.append([np.array(flappedImage), np.array([0,0,0,1,0,0])])\n",
        "      elif name == \"Tennis\":\n",
        "        Tennis.append([np.array(flappedImage), np.array([0,0,0,0,1,0])])\n",
        "      elif name == \"Yoga\":\n",
        "        Yoga.append([np.array(flappedImage), np.array([0,0,0,0,0,1])])\n",
        "\n",
        "augmentationFlipHorizontal(Basketball,\"Basketball\")\n",
        "augmentationFlipHorizontal(Football,\"Football\")\n",
        "augmentationFlipHorizontal(Rowing,\"Rowing\")\n",
        "augmentationFlipHorizontal(Swimming,\"Swimming\")\n",
        "augmentationFlipHorizontal(Tennis,\"Tennis\")\n",
        "augmentationFlipHorizontal(Yoga,\"Yoga\")\n",
        "print(\"number of each class after augmentation\")\n",
        "print(len(Basketball))\n",
        "print(len(Football))\n",
        "print(len(Rowing))\n",
        "print(len(Swimming))\n",
        "print(len(Tennis))\n",
        "print(len(Yoga))\n",
        "def create_label(image_name):\n",
        "    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n",
        "    word_label = image_name.split('_')[0]\n",
        "    if word_label == 'Basketball':\n",
        "        return np.array([1,0,0,0,0,0])\n",
        "    elif word_label == 'Football':\n",
        "        return np.array([0,1,0,0,0,0])\n",
        "    elif word_label == 'Rowing':\n",
        "        return np.array([0,0,1,0,0,0])\n",
        "    elif word_label == 'Swimming':\n",
        "        return np.array([0,0,0,1,0,0])\n",
        "    elif word_label == 'Tennis':\n",
        "        return np.array([0,0,0,0,1,0])\n",
        "    elif word_label == 'Yoga':\n",
        "        return np.array([0,0,0,0,0,1])\n",
        "\n",
        "\n",
        "train = []\n",
        "def createTrainData(data):\n",
        "  for i in data:\n",
        "    train.append(i)\n",
        "\n",
        "\n",
        "createTrainData(Basketball)\n",
        "createTrainData(Football)\n",
        "createTrainData(Rowing)\n",
        "createTrainData(Swimming)\n",
        "createTrainData(Tennis)\n",
        "createTrainData(Yoga)\n",
        "\n",
        "shuffle(train)\n",
        "print(\"shape of train data\")\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "y_train = np.array([i[1] for i in train])\n",
        "print(X_train.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train ,\n",
        "                                   random_state=104, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "ZI2Axf87rqe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f1e475-9ed1-4284-8a1e-5f6fa5545cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1681/1681 [00:07<00:00, 236.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "number of each class\n",
            "196\n",
            "400\n",
            "202\n",
            "240\n",
            "185\n",
            "458\n",
            "number of each class after augmentation\n",
            "458\n",
            "458\n",
            "458\n",
            "458\n",
            "458\n",
            "458\n",
            "shape of train data\n",
            "(2748, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    \n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "    \n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "GPOF7pIKxLuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)"
      ],
      "metadata": {
        "id": "fBvhNUo6dIxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
        "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=192,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=96,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_3b')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=192,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=208,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=48,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4a')\n",
        "\n",
        "\n",
        "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(1024, activation='relu')(x1)\n",
        "x1 = Dropout(0.7)(x1)\n",
        "x1 = Dense(6, activation='softmax', name='auxilliary_output_1')(x1)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=160,\n",
        "                     filters_3x3_reduce=112,\n",
        "                     filters_3x3=224,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4b')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=256,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4c')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=112,\n",
        "                     filters_3x3_reduce=144,\n",
        "                     filters_3x3=288,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4d')\n",
        "\n",
        "\n",
        "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
        "x2 = Flatten()(x2)\n",
        "x2 = Dense(1024, activation='relu')(x2)\n",
        "x2 = Dropout(0.7)(x2)\n",
        "x2 = Dense(6, activation='softmax', name='auxilliary_output_2')(x2)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_4e')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=384,\n",
        "                     filters_3x3_reduce=192,\n",
        "                     filters_3x3=384,\n",
        "                     filters_5x5_reduce=48,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5b')\n",
        "\n",
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Dense(6, activation='softmax', name='output')(x)"
      ],
      "metadata": {
        "id": "pLfWHYZsdVlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Model(input_layer, [x, x1, x2], name='inception_v1')\n"
      ],
      "metadata": {
        "id": "xbyFWbKZdfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "initial_lrate = 0.01\n",
        "\n",
        "def decay(epoch, steps=100):\n",
        "    initial_lrate = 0.01\n",
        "    drop = 0.96\n",
        "    epochs_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate\n",
        "\n",
        "sgd = SGD(learning_rate=initial_lrate, momentum=0.9, nesterov=False)\n",
        "\n",
        "lr_sc = LearningRateScheduler(decay, verbose=1)\n",
        "\n",
        "model.compile(loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'], loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_stMv_QE9vws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, [y_train, y_train, y_train], validation_data=(X_test, [y_test, y_test, y_test]), epochs=25, batch_size=256, callbacks=[lr_sc])\n",
        "model.save('inception.tfl')"
      ],
      "metadata": {
        "id": "KR7jd023xo2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e221ac1-45fc-4767-8c3e-01648df07655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 2061 samples, validate on 687 samples\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/25\n",
            "2061/2061 [==============================] - 7s 3ms/sample - loss: 0.7250 - output_loss: 0.4492 - auxilliary_output_1_loss: 0.4589 - auxilliary_output_2_loss: 0.4555 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8328 - auxilliary_output_2_acc: 0.8321 - val_loss: 0.7078 - val_output_loss: 0.4428 - val_auxilliary_output_1_loss: 0.4428 - val_auxilliary_output_2_loss: 0.4412 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 2/25\n",
            "2061/2061 [==============================] - 7s 3ms/sample - loss: 0.7192 - output_loss: 0.4478 - auxilliary_output_1_loss: 0.4539 - auxilliary_output_2_loss: 0.4547 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8329 - auxilliary_output_2_acc: 0.8332 - val_loss: 0.7040 - val_output_loss: 0.4399 - val_auxilliary_output_1_loss: 0.4407 - val_auxilliary_output_2_loss: 0.4410 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 3/25\n",
            "2061/2061 [==============================] - 7s 3ms/sample - loss: 0.7168 - output_loss: 0.4425 - auxilliary_output_1_loss: 0.4517 - auxilliary_output_2_loss: 0.4510 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8324 - auxilliary_output_2_acc: 0.8331 - val_loss: 0.7041 - val_output_loss: 0.4401 - val_auxilliary_output_1_loss: 0.4397 - val_auxilliary_output_2_loss: 0.4397 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 4/25\n",
            "2061/2061 [==============================] - 7s 3ms/sample - loss: 0.7193 - output_loss: 0.4477 - auxilliary_output_1_loss: 0.4565 - auxilliary_output_2_loss: 0.4534 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8324 - auxilliary_output_2_acc: 0.8329 - val_loss: 0.7040 - val_output_loss: 0.4410 - val_auxilliary_output_1_loss: 0.4400 - val_auxilliary_output_2_loss: 0.4405 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 5/25\n",
            "2061/2061 [==============================] - 7s 3ms/sample - loss: 0.7166 - output_loss: 0.4451 - auxilliary_output_1_loss: 0.4510 - auxilliary_output_2_loss: 0.4503 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8330 - auxilliary_output_2_acc: 0.8323 - val_loss: 0.7047 - val_output_loss: 0.4404 - val_auxilliary_output_1_loss: 0.4397 - val_auxilliary_output_2_loss: 0.4396 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 6/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7175 - output_loss: 0.4473 - auxilliary_output_1_loss: 0.4547 - auxilliary_output_2_loss: 0.4574 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8331 - auxilliary_output_2_acc: 0.8330 - val_loss: 0.7033 - val_output_loss: 0.4393 - val_auxilliary_output_1_loss: 0.4394 - val_auxilliary_output_2_loss: 0.4394 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 7/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7168 - output_loss: 0.4478 - auxilliary_output_1_loss: 0.4528 - auxilliary_output_2_loss: 0.4534 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8332 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7033 - val_output_loss: 0.4398 - val_auxilliary_output_1_loss: 0.4402 - val_auxilliary_output_2_loss: 0.4401 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0100\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 8/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7167 - output_loss: 0.4461 - auxilliary_output_1_loss: 0.4523 - auxilliary_output_2_loss: 0.4525 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8333 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7041 - val_output_loss: 0.4402 - val_auxilliary_output_1_loss: 0.4396 - val_auxilliary_output_2_loss: 0.4400 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 9/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7151 - output_loss: 0.4460 - auxilliary_output_1_loss: 0.4509 - auxilliary_output_2_loss: 0.4517 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8335 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7035 - val_output_loss: 0.4395 - val_auxilliary_output_1_loss: 0.4394 - val_auxilliary_output_2_loss: 0.4393 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 10/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7151 - output_loss: 0.4437 - auxilliary_output_1_loss: 0.4499 - auxilliary_output_2_loss: 0.4544 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8334 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7026 - val_output_loss: 0.4395 - val_auxilliary_output_1_loss: 0.4391 - val_auxilliary_output_2_loss: 0.4393 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 11/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7156 - output_loss: 0.4470 - auxilliary_output_1_loss: 0.4516 - auxilliary_output_2_loss: 0.4530 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8333 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7027 - val_output_loss: 0.4396 - val_auxilliary_output_1_loss: 0.4392 - val_auxilliary_output_2_loss: 0.4392 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 12/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7138 - output_loss: 0.4435 - auxilliary_output_1_loss: 0.4487 - auxilliary_output_2_loss: 0.4495 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8330 - auxilliary_output_2_acc: 0.8330 - val_loss: 0.7033 - val_output_loss: 0.4397 - val_auxilliary_output_1_loss: 0.4396 - val_auxilliary_output_2_loss: 0.4388 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 13/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7144 - output_loss: 0.4437 - auxilliary_output_1_loss: 0.4509 - auxilliary_output_2_loss: 0.4495 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8331 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7015 - val_output_loss: 0.4387 - val_auxilliary_output_1_loss: 0.4378 - val_auxilliary_output_2_loss: 0.4382 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 14/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7114 - output_loss: 0.4425 - auxilliary_output_1_loss: 0.4455 - auxilliary_output_2_loss: 0.4474 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8340 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.7010 - val_output_loss: 0.4385 - val_auxilliary_output_1_loss: 0.4388 - val_auxilliary_output_2_loss: 0.4381 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 15/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7108 - output_loss: 0.4413 - auxilliary_output_1_loss: 0.4449 - auxilliary_output_2_loss: 0.4452 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8340 - auxilliary_output_2_acc: 0.8334 - val_loss: 0.6999 - val_output_loss: 0.4378 - val_auxilliary_output_1_loss: 0.4363 - val_auxilliary_output_2_loss: 0.4372 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0096\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 16/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7114 - output_loss: 0.4443 - auxilliary_output_1_loss: 0.4533 - auxilliary_output_2_loss: 0.4477 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8337 - auxilliary_output_2_acc: 0.8335 - val_loss: 0.7001 - val_output_loss: 0.4375 - val_auxilliary_output_1_loss: 0.4381 - val_auxilliary_output_2_loss: 0.4368 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8333 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0092\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 17/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7107 - output_loss: 0.4419 - auxilliary_output_1_loss: 0.4442 - auxilliary_output_2_loss: 0.4435 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8339 - auxilliary_output_2_acc: 0.8335 - val_loss: 0.6966 - val_output_loss: 0.4359 - val_auxilliary_output_1_loss: 0.4345 - val_auxilliary_output_2_loss: 0.4348 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8360 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0092\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 18/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7071 - output_loss: 0.4342 - auxilliary_output_1_loss: 0.4365 - auxilliary_output_2_loss: 0.4409 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8350 - auxilliary_output_2_acc: 0.8337 - val_loss: 0.7004 - val_output_loss: 0.4361 - val_auxilliary_output_1_loss: 0.4406 - val_auxilliary_output_2_loss: 0.4375 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8384 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0092\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 19/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.7077 - output_loss: 0.4403 - auxilliary_output_1_loss: 0.4505 - auxilliary_output_2_loss: 0.4513 - output_acc: 0.8333 - auxilliary_output_1_acc: 0.8338 - auxilliary_output_2_acc: 0.8328 - val_loss: 0.6889 - val_output_loss: 0.4299 - val_auxilliary_output_1_loss: 0.4285 - val_auxilliary_output_2_loss: 0.4310 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8367 - val_auxilliary_output_2_acc: 0.8333 - lr: 0.0092\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 20/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6995 - output_loss: 0.4316 - auxilliary_output_1_loss: 0.4349 - auxilliary_output_2_loss: 0.4403 - output_acc: 0.8336 - auxilliary_output_1_acc: 0.8354 - auxilliary_output_2_acc: 0.8335 - val_loss: 0.6847 - val_output_loss: 0.4271 - val_auxilliary_output_1_loss: 0.4272 - val_auxilliary_output_2_loss: 0.4309 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8379 - val_auxilliary_output_2_acc: 0.8353 - lr: 0.0092\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 21/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6936 - output_loss: 0.4314 - auxilliary_output_1_loss: 0.4365 - auxilliary_output_2_loss: 0.4393 - output_acc: 0.8340 - auxilliary_output_1_acc: 0.8353 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.6738 - val_output_loss: 0.4196 - val_auxilliary_output_1_loss: 0.4208 - val_auxilliary_output_2_loss: 0.4243 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8387 - val_auxilliary_output_2_acc: 0.8360 - lr: 0.0092\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 22/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6815 - output_loss: 0.4218 - auxilliary_output_1_loss: 0.4299 - auxilliary_output_2_loss: 0.4371 - output_acc: 0.8345 - auxilliary_output_1_acc: 0.8369 - auxilliary_output_2_acc: 0.8337 - val_loss: 0.6755 - val_output_loss: 0.4215 - val_auxilliary_output_1_loss: 0.4238 - val_auxilliary_output_2_loss: 0.4233 - val_output_acc: 0.8333 - val_auxilliary_output_1_acc: 0.8384 - val_auxilliary_output_2_acc: 0.8348 - lr: 0.0092\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 23/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6775 - output_loss: 0.4213 - auxilliary_output_1_loss: 0.4300 - auxilliary_output_2_loss: 0.4328 - output_acc: 0.8367 - auxilliary_output_1_acc: 0.8368 - auxilliary_output_2_acc: 0.8354 - val_loss: 0.6797 - val_output_loss: 0.4240 - val_auxilliary_output_1_loss: 0.4225 - val_auxilliary_output_2_loss: 0.4238 - val_output_acc: 0.8406 - val_auxilliary_output_1_acc: 0.8328 - val_auxilliary_output_2_acc: 0.8401 - lr: 0.0092\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 24/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6770 - output_loss: 0.4191 - auxilliary_output_1_loss: 0.4329 - auxilliary_output_2_loss: 0.4305 - output_acc: 0.8395 - auxilliary_output_1_acc: 0.8362 - auxilliary_output_2_acc: 0.8333 - val_loss: 0.6558 - val_output_loss: 0.4069 - val_auxilliary_output_1_loss: 0.4173 - val_auxilliary_output_2_loss: 0.4117 - val_output_acc: 0.8455 - val_auxilliary_output_1_acc: 0.8394 - val_auxilliary_output_2_acc: 0.8375 - lr: 0.0088\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 25/25\n",
            "2061/2061 [==============================] - 7s 4ms/sample - loss: 0.6633 - output_loss: 0.4101 - auxilliary_output_1_loss: 0.4236 - auxilliary_output_2_loss: 0.4206 - output_acc: 0.8441 - auxilliary_output_1_acc: 0.8377 - auxilliary_output_2_acc: 0.8389 - val_loss: 0.6725 - val_output_loss: 0.4220 - val_auxilliary_output_1_loss: 0.4189 - val_auxilliary_output_2_loss: 0.4162 - val_output_acc: 0.8375 - val_auxilliary_output_1_acc: 0.8384 - val_auxilliary_output_2_acc: 0.8469 - lr: 0.0088\n"
          ]
        }
      ]
    }
  ]
}