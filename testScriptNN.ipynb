{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjxp54BdPB/vtN5HM1aC/J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toka-amer/Sport-Image-Classification/blob/main/testScriptNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive/',force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kReNlAqEQHOx",
        "outputId": "e5dfadbe-00bd-46c7-f472-6f146b529ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/MyDrive/MyDrive/NNDataset.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXfDSmpKQJIu",
        "outputId": "c7e2607b-9d31-418c-e109-7ac987c7e31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/MyDrive/MyDrive/NNDataset.zip\n",
            "replace Test/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = '/content/Test'\n",
        "inceptionPath = '/content/MyDrive/MyDrive/Models/inception.tfl'\n",
        "cnnPath = '/content/MyDrive/MyDrive/Models/cnn.tfl'\n",
        "vggPath = '/content/MyDrive/MyDrive/Models/vgg.tfl'\n",
        "alexnetPath = '/content/MyDrive/MyDrive/Models/alexnet.tfl'\n",
        "resnet50Path = '/content/MyDrive/MyDrive/Models/resnet50.tfl'"
      ],
      "metadata": {
        "id": "aEXxDlMqQNe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from random import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os,cv2\n",
        "from IPython.display import Image\n",
        "from keras.preprocessing import image\n",
        "from keras import optimizers\n",
        "from keras import layers,models\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.optimizers import rmsprop_v2\n",
        "\n",
        "def loadCNN():\n",
        "  ops.reset_default_graph()\n",
        "  conv_input = input_data(shape=[None, 64, 64, 3], name='input')\n",
        "  conv1 = conv_2d(conv_input, 32, 5, activation='relu')\n",
        "  pool1 = max_pool_2d(conv1, 5)\n",
        "\n",
        "  conv2 = conv_2d(pool1, 64, 5, activation='relu')\n",
        "  pool2 = max_pool_2d(conv2, 5)\n",
        "\n",
        "  conv3 = conv_2d(pool2, 128, 5, activation='relu')\n",
        "  pool3 = max_pool_2d(conv3, 5)\n",
        "\n",
        "  conv4 = conv_2d(pool3, 64, 5, activation='relu')\n",
        "  pool4 = max_pool_2d(conv4, 5)\n",
        "\n",
        "  conv5 = conv_2d(pool4, 32, 5, activation='relu')\n",
        "  pool5 = max_pool_2d(conv5, 5)\n",
        "\n",
        "  fully_layer = fully_connected(pool5, 1024, activation='relu')\n",
        "  fully_layer = dropout(fully_layer, 0.5)\n",
        "\n",
        "  cnn_layers = fully_connected(fully_layer, 6, activation='softmax')\n",
        "\n",
        "  cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=0.001, loss='binary_crossentropy', name='targets')\n",
        "  model = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=1)\n",
        "  model.load(cnnPath)\n",
        "  return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBCbJMjZTVJ3",
        "outputId": "d1416c31-be33-409f-d2d4-dd254b653a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from random import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os,cv2\n",
        "from IPython.display import Image\n",
        "from keras.preprocessing import image\n",
        "from keras import optimizers\n",
        "from keras import layers,models\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.optimizers import rmsprop_v2\n",
        "\n",
        "def loadVGG16():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "  model.add(layers.MaxPool2D((2,2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512,activation='relu'))\n",
        "  model.add(layers.Dense(6,activation='softmax'))\n",
        "  model = tf.keras.models.load_model(vggPath)\n",
        "  return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpkdk4NATfTo",
        "outputId": "f7cac3a1-6701-4a7c-94bf-1b1cc289efca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from random import shuffle\n",
        "\n",
        "def loadAlexNet():\n",
        "  model=keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1024,activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(6,activation='softmax')  \n",
        "    \n",
        "    \n",
        "  ])\n",
        "  model = tf.keras.models.load_model(alexnetPath)\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPefwxsXTw8h",
        "outputId": "f9145c1e-292b-4eb6-b30b-3a0b0c6791b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "   \n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])# SKIP Connection\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "   \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def loadResNet50():\n",
        "  X_input = Input((224, 224, 3))\n",
        "\n",
        "  X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "  X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "  X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "  X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "  X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "  X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n",
        "  \n",
        "  model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "  model = tf.keras.models.load_model(resnet50Path)\n",
        "  return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozcSt6KfUAuY",
        "outputId": "83919474-c45a-4b2f-ff7b-e3f4c7a5e857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrmWK4MeA57I",
        "outputId": "ae31f6cf-c752-436c-cf9c-6771b83f8e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "!pip install tflearn\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPool2D,  \\\n",
        "    Dropout, Dense, Input, concatenate,      \\\n",
        "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
        "    Flatten\n",
        "from keras.datasets import cifar10 \n",
        "from keras import backend as K \n",
        "from keras.utils import np_utils\n",
        "import math \n",
        "from keras.optimizers import SGD \n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from random import shuffle\n",
        "\n",
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "    \n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    \n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "    \n",
        "    return output\n",
        "\n",
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)\n",
        "\n",
        "def loadInception():\n",
        "  input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "  x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
        "  x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "  x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
        "  x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
        "  x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=64,\n",
        "                      filters_3x3_reduce=96,\n",
        "                      filters_3x3=128,\n",
        "                      filters_5x5_reduce=16,\n",
        "                      filters_5x5=32,\n",
        "                      filters_pool_proj=32,\n",
        "                      name='inception_3a')\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=128,\n",
        "                      filters_3x3_reduce=128,\n",
        "                      filters_3x3=192,\n",
        "                      filters_5x5_reduce=32,\n",
        "                      filters_5x5=96,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_3b')\n",
        "\n",
        "  x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=192,\n",
        "                      filters_3x3_reduce=96,\n",
        "                      filters_3x3=208,\n",
        "                      filters_5x5_reduce=16,\n",
        "                      filters_5x5=48,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_4a')\n",
        "\n",
        "\n",
        "  x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "  x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
        "  x1 = Flatten()(x1)\n",
        "  x1 = Dense(1024, activation='relu')(x1)\n",
        "  x1 = Dropout(0.7)(x1)\n",
        "  x1 = Dense(6, activation='softmax', name='auxilliary_output_1')(x1)\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=160,\n",
        "                      filters_3x3_reduce=112,\n",
        "                      filters_3x3=224,\n",
        "                      filters_5x5_reduce=24,\n",
        "                      filters_5x5=64,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_4b')\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=128,\n",
        "                      filters_3x3_reduce=128,\n",
        "                      filters_3x3=256,\n",
        "                      filters_5x5_reduce=24,\n",
        "                      filters_5x5=64,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_4c')\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=112,\n",
        "                      filters_3x3_reduce=144,\n",
        "                      filters_3x3=288,\n",
        "                      filters_5x5_reduce=32,\n",
        "                      filters_5x5=64,\n",
        "                      filters_pool_proj=64,\n",
        "                      name='inception_4d')\n",
        "\n",
        "\n",
        "  x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "  x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
        "  x2 = Flatten()(x2)\n",
        "  x2 = Dense(1024, activation='relu')(x2)\n",
        "  x2 = Dropout(0.7)(x2)\n",
        "  x2 = Dense(6, activation='softmax', name='auxilliary_output_2')(x2)\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=256,\n",
        "                      filters_3x3_reduce=160,\n",
        "                      filters_3x3=320,\n",
        "                      filters_5x5_reduce=32,\n",
        "                      filters_5x5=128,\n",
        "                      filters_pool_proj=128,\n",
        "                      name='inception_4e')\n",
        "\n",
        "  x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=256,\n",
        "                      filters_3x3_reduce=160,\n",
        "                      filters_3x3=320,\n",
        "                      filters_5x5_reduce=32,\n",
        "                      filters_5x5=128,\n",
        "                      filters_pool_proj=128,\n",
        "                      name='inception_5a')\n",
        "\n",
        "  x = inception_module(x,\n",
        "                      filters_1x1=384,\n",
        "                      filters_3x3_reduce=192,\n",
        "                      filters_3x3=384,\n",
        "                      filters_5x5_reduce=48,\n",
        "                      filters_5x5=128,\n",
        "                      filters_pool_proj=128,\n",
        "                      name='inception_5b')\n",
        "\n",
        "  x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  x = Dense(6, activation='softmax', name='output')(x)\n",
        "  model = Model(input_layer, [x, x1, x2], name='inception_v1')\n",
        "  model = tf.keras.models.load_model(resnet50Path)\n",
        "  return model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictTestLabel(model,X_test):\n",
        "  predictionTest = []\n",
        "  prediction = model.predict(X_test)\n",
        "  i = 0\n",
        "  for img in tqdm(os.listdir(TEST_DIR)):\n",
        "    pred = np.argmax(prediction[i])\n",
        "    predictionTest.append([img,pred])\n",
        "    i += 1\n",
        "  return predictionTest\n",
        "\n",
        "def createCSVFile(path,predictionTest):\n",
        "   with open(path, 'w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"image_name\",\"label\"])\n",
        "    for i in predictionTest:\n",
        "      writer.writerow(i)\n",
        "    file.close() "
      ],
      "metadata": {
        "id": "WScz3yOHHgTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=[]\n",
        "for img in tqdm(os.listdir(TEST_DIR)):\n",
        "    path = os.path.join(TEST_DIR, img)\n",
        "    img_data = cv2.imread(path,1)\n",
        "    img_data = cv2.resize(img_data, (224, 224))\n",
        "    test.append(np.array(img_data))\n",
        "\n",
        "X_test = np.array([i for i in test]).reshape(-1, 224, 224, 3)\n",
        "\n",
        "\n",
        "inception = loadInception()\n",
        "prediction = predictTestLabel(inception,X_test)\n",
        "createCSVFile('/content/Inception.csv',prediction)\n",
        "dfInception = pd.read_csv('/content/Inception.csv')\n",
        "print(\"////////////Inception///////////////\")\n",
        "print(dfInception)\n",
        "\n",
        "\n",
        "ResNet50 = loadResNet50()\n",
        "prediction = predictTestLabel(ResNet50,X_test)\n",
        "createCSVFile('/content/ResNet50.csv',prediction)\n",
        "dfResNet50 = pd.read_csv('/content/ResNet50.csv')\n",
        "print(\"////////////ResNet50///////////////\")\n",
        "print(dfResNet50)\n",
        "\n",
        "###change size of images to 64x64###\n",
        "test = []\n",
        "for img in tqdm(os.listdir(TEST_DIR)):\n",
        "    path = os.path.join(TEST_DIR, img)\n",
        "    img_data = cv2.imread(path,1)\n",
        "    img_data = cv2.resize(img_data, (64, 64))\n",
        "    test.append(np.array(img_data))\n",
        "\n",
        "X_test = np.array([i for i in test]).reshape(-1, 64, 64, 3)\n",
        "\n",
        "\n",
        "AlexNet = loadAlexNet()\n",
        "prediction = predictTestLabel(AlexNet,X_test)\n",
        "createCSVFile('/content/AlexNet.csv',prediction)\n",
        "dfAlexNet = pd.read_csv('/content/AlexNet.csv')\n",
        "print(\"////////////AlexNet///////////////\")\n",
        "print(dfAlexNet)\n",
        "\n",
        "\n",
        "CNN = loadCNN()\n",
        "prediction = predictTestLabel(CNN,X_test)\n",
        "createCSVFile('/content/CNN.csv',prediction)\n",
        "dfCNN = pd.read_csv('/content/CNN.csv')\n",
        "print(\"////////////CNN///////////////\")\n",
        "print(dfCNN)\n",
        "\n",
        "\n",
        "VGG16 = loadVGG16()\n",
        "prediction = predictTestLabel(VGG16,X_test)\n",
        "createCSVFile('/content/VGG16.csv',prediction)\n",
        "dfVGG16 = pd.read_csv('/content/VGG16.csv')\n",
        "print(\"////////////VGG16///////////////\")\n",
        "print(dfVGG16)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfFvQQVBDrtZ",
        "outputId": "4fb008d3-1473-442f-9bc6-12affd6e9aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688/688 [00:09<00:00, 70.96it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "100%|██████████| 688/688 [00:00<00:00, 171185.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "////////////Inception///////////////\n",
            "    image_name  label\n",
            "0      253.jpg      4\n",
            "1      312.jpg      0\n",
            "2      181.jpg      2\n",
            "3      224.jpg      2\n",
            "4      614.jpg      4\n",
            "..         ...    ...\n",
            "683    539.jpg      0\n",
            "684    292.jpg      4\n",
            "685    141.jpg      2\n",
            "686    143.jpg      5\n",
            "687     40.jpg      0\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "100%|██████████| 688/688 [00:00<00:00, 199259.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "////////////ResNet50///////////////\n",
            "    image_name  label\n",
            "0      253.jpg      4\n",
            "1      312.jpg      0\n",
            "2      181.jpg      2\n",
            "3      224.jpg      2\n",
            "4      614.jpg      4\n",
            "..         ...    ...\n",
            "683    539.jpg      0\n",
            "684    292.jpg      4\n",
            "685    141.jpg      2\n",
            "686    143.jpg      5\n",
            "687     40.jpg      0\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688/688 [00:06<00:00, 101.85it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "100%|██████████| 688/688 [00:00<00:00, 84091.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "////////////AlexNet///////////////\n",
            "    image_name  label\n",
            "0      253.jpg      2\n",
            "1      312.jpg      1\n",
            "2      181.jpg      2\n",
            "3      224.jpg      2\n",
            "4      614.jpg      5\n",
            "..         ...    ...\n",
            "683    539.jpg      1\n",
            "684    292.jpg      4\n",
            "685    141.jpg      2\n",
            "686    143.jpg      5\n",
            "687     40.jpg      5\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688/688 [00:00<00:00, 135950.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "////////////CNN///////////////\n",
            "    image_name  label\n",
            "0      253.jpg      2\n",
            "1      312.jpg      2\n",
            "2      181.jpg      2\n",
            "3      224.jpg      2\n",
            "4      614.jpg      2\n",
            "..         ...    ...\n",
            "683    539.jpg      2\n",
            "684    292.jpg      2\n",
            "685    141.jpg      2\n",
            "686    143.jpg      5\n",
            "687     40.jpg      2\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "100%|██████████| 688/688 [00:00<00:00, 131352.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "////////////VGG16///////////////\n",
            "    image_name  label\n",
            "0      253.jpg      5\n",
            "1      312.jpg      1\n",
            "2      181.jpg      2\n",
            "3      224.jpg      2\n",
            "4      614.jpg      5\n",
            "..         ...    ...\n",
            "683    539.jpg      1\n",
            "684    292.jpg      1\n",
            "685    141.jpg      2\n",
            "686    143.jpg      4\n",
            "687     40.jpg      1\n",
            "\n",
            "[688 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}